datosClust[, c(5,6,7)] <- sapply(dat[, c(5,6,7)], as.numeric)
datosClust[, c(5,6,7)] <- sapply(datosClust[, c(5,6,7)], as.numeric)
wss[i] <- sum(kmeans(datosClust, centers=i)$withinss)
wss <- (nrow(datosClust)-1)*sum(apply(datosClust,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(datosClust, centers=i)$withinss)
datosClust = merge(newdata16,newdata17, all.x=T)
datosClust[, c(5,6,7)] <- sapply(datosClust[, c(5,6,7)], as.numeric)
datosClust[, c(5,6,8)] <- sapply(datosClust[, c(5,6,8)], as.numeric)
# ---------------------------------
wss <- (nrow(datosClust)-1)*sum(apply(datosClust,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(datosClust, centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")
# ---------------------------------
wss <- (nrow(datosClust)-1)*sum(apply(datosClust,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(datosClust, centers=i)$withinss)
#transformando data
data = as.data.frame(unclass(datosClust))
# Eliminando todos los NAs
myData = na.omit(data)
#escalar y centrar data
scaled_data = as.matrix(scale(myData))
datosClust[, c(1:8)] <- sapply(datosClust[, c(1:8)], as.numeric)
#Elbow method
# ---------------------------------
wss <- (nrow(datosClust)-1)*sum(apply(datosClust,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(datosClust, centers=i)$withinss)
#transformando data
data = as.data.frame(unclass(datosClust))
# Eliminando todos los NAs
myData = na.omit(data)
#escalar y centrar data
scaled_data = as.matrix(scale(myData))
#Elbow method
# ---------------------------------
wss <- (nrow(scaled_data)-1)*sum(apply(scaled_data,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(scaled_data, centers=i)$withinss)
#Elbow Method con data escalada
set.seed(123)
k.max <- 15
dati <- scaled_data
wss <- sapply(1:k.max,
function(k){kmeans(dati, k, nstart=50,iter.max = 15 )$tot.withinss})
wss
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
set.seed(123)
k.max <- 15
dati <- scaled_data
wss <- sapply(1:k.max,
function(k){kmeans(dati, k, nstart=50,iter.max = 15 )$tot.withinss})
wss
#transformando data
data = as.data.frame(unclass(datosClust))
# Eliminando todos los NAs
myData = na.omit(data)
View(myData)
wss <- (nrow(myData)-1)*sum(apply(myData,2,var))
for (i in 2:10)
wss[i] <- sum(kmeans(myData, centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")
d_clust <- Mclust(as.matrix(myData), G=1:15,
modelNames = mclust.options("emModelNames"))
d_clust$BIC
plot(d_clust)
# --------
library(foreign)#lectura archivos .sav
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
d_clust <- Mclust(as.matrix(myData), G=1:15,
modelNames = mclust.options("emModelNames"))
d_clust$BIC
plot(d_clust)
g1
km<-kmeans(myData,2)
myData$grupo<-as.factor(km$cluster)
g1<- myData[myData$grupo==1,]
g2<- myData[myData$grupo==2,]
g1
summary(g1)
summary(g2)
library(foreign)#lectura archivos .sav
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
#IVETTE
dataset16 = read.spss(file.choose(), to.data.frame=TRUE)
dataset17 = read.spss(file.choose(), to.data.frame=TRUE)
myvars16 <- c("AGR_EDAD", "VIC_EDAD", "AGR_GURPET", "VIC_GRUPET", "AGRESORES_OTROS_TOTAL", "INST_DONDE_DENUNCIO", "DEPTO_MCPIO", "TOTAL_HIJOS", "OTRAS_VICTIMAS", "AGR_ALFAB", "AGR_TRABAJA", "HEC_DEPTOMCPIO")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
myvars17 <- c("AGR_EDAD", "VIC_EDAD", "AGR_GURPET", "VIC_GRUPET", "AGRESORES_OTROS_TOTAL", "INST_DONDE_DENUNCIO", "DEPTO_MCPIO", "TOTAL_HIJOS", "OTRAS_VICTIMAS", "AGR_ALFAB", "AGR_TRABAJA", "HEC_DEPTOMCPIO")
newdata17 <- select(dataset17, one_of(myvars17))
newdata17
datosP = merge(newdata16,newdata17, all.x=TRUE)
library(caret)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(e1071)
library(foreign)#lectura archivos .sav
library(caret)
library(e1071)
#IVETTE
#Test and train
set.seed(123)
porcentaje<-0.7
datosP$y<- as.numeric(datosP$Type)
datosP$y<- as.numeric(datosP$Type)
trainRowsNumber<-sample(1:nrow(datosP),70/100*nrow(datosP))
train<-datosP[trainRowsNumber,]
test<-datosP[-trainRowsNumber,]
corte <- sample(nrow(datosP),nrow(datosP)*porcentaje)
test = na.omit(test)
train = na.omit(train)
rownames(test) <- c()
rownames(train) <- c()
View(test)
#Plot the dataset
plot(train,pch=16)
#Linear regression
model <- lm(AGR_ALFAB ~ ., train)
#Plot the model using abline
abline(model)
train$AGR_ALFAB <- as.factor(train$AGR_ALFAB)
#M1
model_svm <- svm(AGR_ALFAB ~ . , train)
model_svm
pred <- predict(model_svm, test[,1:ncol(test)])
confusionMatrix(as.factor(test$AGR_ALFAB),pred)
library(foreign)#lectura archivos .sav
library(caret)
library(e1071)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS);
library(neuralnet)
library(ggplot2)
install.packages("nnet")
install.packages("nnet")
install.packages("RWeka")
install.packages("neural")
install.packages("dummies")
install.packages("neuralnet")
install.packages("MASS")
library(foreign)#lectura archivos .sav
library(caret)
library(e1071)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS);
library(ggplot2)
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
nms  <- names(train)
frml <- as.formula(paste("AGR_ALFAB ~", paste(nms[!nms %in% "AGR_ALFAB"], collapse = " + ")))
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
modelo.nn <- neuralnet(frml,
data          = train,
hidden        = c(5,2), # ver Notas para detalle
threshold     = 0.05,   # ver Notas para detalle
algorithm     = "rprop+"
)
#Regresion simple
modelo_simple <- lm(data = datosP, formula = AGR_ALFAB ~ .)
modelo_simple
names(modelo_simple)
summary(modelo_simple)
plot(modelo_simple)
plot(x = lstat, y = medv, main = "medv vs lstat", pch = 20, col = "grey30")
modelo_simple
plot(x = AGR_ALFAB, main = "medv vs lstat", pch = 20, col = "grey30")
View(Boston)
datosP)
attach(datosP)
plot(x = AGR_ALFAB, main = "AGR_ALFAB vs . ", pch = 20, col = "grey30")
plot(x = AGR_ALFAB, main = "AGR_ALFAB vs . ", pch = 20, col = "grey30")
abline(modelo_simple, lwd = 3, col = "red")
#Regresion simple
modelo_simple <- lm(data = datosP, formula = AGR_TRABAJA ~ .)
attach(datosP)
plot(x = AGR_TRABAJA, main = "AGR_TRABAJA vs . ", pch = 20, col = "grey30")
abline(modelo_simple, lwd = 3, col = "red")
library(foreign)#lectura archivos .sav
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
datos = merge(newdata16,newdata17, all.x=T)
summary(datosP)
# ----------------------------------------------------------------------------------------------------------------------------------------------------------------
# Summary
# ---------------------
summary(dataset16)
myvars16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
myvars17 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata17 <- select(dataset17, one_of(myvars17))
newdata17
datosP = merge(newdata16,newdata17, all.x=TRUE)
summary(datosP)
myvars16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
summary(newdata16)
#KIUVOLEWEY
myvars16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
newdata16 <- select(dataset16, one_of(myvars16))
newdata16
summary(newdata16)
myva16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata16 <- select(dataset16, one_of(myva16))
library(foreign)#lectura archivos .sav
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
myva16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata16 <- select(dataset16, one_of(myva16))
#KIUVOLEWEY
myva16 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata16 <- select(dataset16, one_of(myva16))
myva17 <- c("AGR_SEXO", "AGR_EDAD", "AGR_GURPET", "AGR_ESCOLARIDAD", "AGR_EST_CIV", "AGR_ALFAB", "AGR_TRABAJA")
ndata17 <- select(dataset17, one_of(myva17))
datP = merge(ndata16,ndata17, all.x=TRUE)
summary(datP)
View(dataset16)
View(dataset17)
View(dataset16)
newDataAGR16 <- dataset16[,c("AGR_SEXO", "AGR_EDAD", "AGR_ESCOLARIDAD", "AGR_ALFAB", "AGR_EST_CIV", "AGR_GURPET", "AGR_TRABAJA")]
newDataAGR17 <- dataset17[,c("AGR_SEXO", "AGR_EDAD", "AGR_ESCOLARIDAD", "AGR_ALFAB", "AGR_EST_CIV", "AGR_GURPET", "AGR_TRABAJA")]
newDataVIC16 <- dataset16[,c("VIC_SEXO", "VIC_EDAD", "VIC_ESCOLARIDAD", "VIC_ALFAB", "VIC_EST_CIV", "VIC_GRUPET", "VIC_TRABAJA")]
newDataVIC17 <- dataset17[,c("VIC_SEXO", "VIC_EDAD", "VIC_ESCOLARIDAD", "VIC_ALFAB", "VIC_EST_CIV", "VIC_GRUPET", "VIC_TRABAJA")]
colnames(newDataAGR16) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
colnames(newDataAGR17) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
colnames(newDataVIC16) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
colnames(newDataVIC17) <- c('SEXO', 'EDAD', 'ESCOLARIDAD', 'ALFABETIZACION', 'ESTADO_CIVIL', 'GRUPET', 'TRABAJA')
newDataAGR16 <- na.omit(newDataAGR16)
newDataAGR17 <- na.omit(newDataAGR17)
newDataVIC16 <- na.omit(newDataAGR16)
newDataVIC17 <- na.omit(newDataAGR17)
newDataAGR16$AGROVIC <- '1'
newDataAGR17$AGROVIC <- '1'
newDataVIC16$AGROVIC <- '2'
newDataVIC17$AGROVIC <- '2'
dataAGR <- rbind(newDataAGR16, newDataAGR17, all.x = T)
str(dataAGR)
dataVIC <- rbind(newDataVIC16, newDataVIC17, all.x = T)
str(dataVIC)
allData <- rbind(dataVIC, dataAGR, all.x = T)
allData <- na.omit(allData)
str(newData16) # Tipos de variables de las columnas de la base de datos
allData$AGROVIC <- as.factor(allData$AGROVIC)
summary(allData)
View(allData)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
library(caret)
library(e1071)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS)
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
model_svm
pred <- predict(model_svm, test_data[,1:ncol(test_data)])
confusionMatrix(as.factor(test_data$AGROVIC),pred)
#Plot the dataset
plot(train_data,pch=16)
#Linear regression
model <- lm(AGROVIC ~ ., train_data)
#Linear regression
model <- lm(AGROVIC ~ ., train_data)
#Plot the dataset
plot(train_data,pch=16)
#Plot the dataset
plot(train_data,pch=16)
#Linear regression
model <- lm(AGROVIC ~ ., train_data)
#Plot the model using abline
abline(model)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
library(ggplot2)
library(dplyr)
library(plyr)
library(cluster)
library(fpc)
library(mclust)
library(e1071)#para cmeans
library(factoextra)
library(caret)
library(e1071)
library(rpart)
library(nnet)
library(RWeka)
library(neural)
library(dummies)
library(neuralnet)
library(MASS)
summary(allData)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
pred <- predict(model_svm, test_data[,1:ncol(test_data)])
confusionMatrix(as.factor(test_data$AGROVIC),pred)
summary(train_data)
newDataAGR16 <- dataset16[,c("AGR_DEDICA", "AGR_TRABAJA")]
newDataAGR17 <- dataset17[,c("AGR_DEDICA", "AGR_TRABAJA")]
newDataVIC16 <- dataset16[,c("VIC_DEDICA", "VIC_TRABAJA")]
newDataVIC16 <- dataset16[,c("VIC_DEDICA", "VIC_TRABAJA")]
newDataVIC17 <- dataset17[,c("VIC_DEDICA", "VIC_TRABAJA")]
colnames(newDataAGR16) <- c('DEDICA', 'TRABAJA')
colnames(newDataAGR16) <- c('DEDICA', 'TRABAJA')
colnames(newDataAGR17) <- c('DEDICA', 'TRABAJA')
colnames(newDataVIC16) <- c('DEDICA', 'TRABAJA')
colnames(newDataVIC17) <- c('DEDICA', 'TRABAJA')
newDataAGR16 <- na.omit(newDataAGR16)
newDataAGR17 <- na.omit(newDataAGR17)
newDataVIC16 <- na.omit(newDataAGR16)
newDataVIC17 <- na.omit(newDataAGR17)
newDataAGR16$AGROVIC <- '1'
newDataAGR17$AGROVIC <- '1'
newDataVIC16$AGROVIC <- '2'
newDataVIC17$AGROVIC <- '2'
dataAGR <- rbind(newDataAGR16, newDataAGR17, all.x = T)
str(dataAGR)
dataVIC <- rbind(newDataVIC16, newDataVIC17, all.x = T)
str(dataVIC)
allData <- rbind(dataVIC, dataAGR, all.x = T)
allData <- na.omit(allData)
str(newData16) # Tipos de variables de las columnas de la base de datos
str(newData17)
str(allData)
allData$AGROVIC <- as.factor(allData$AGROVIC)
summary(allData)
porcentaje = 0.7
set.seed(123)
corte <- sample(nrow(allData), nrow(allData)*porcentaje)
train_data = allData[corte,]
test_data = allData[-corte,]
summary(train_data)
#M1
model_svm <- svm(AGROVIC ~ . , train_data)
model_svm
pred <- predict(model_svm, test_data[,1:ncol(test_data)])
confusionMatrix(as.factor(test_data$AGROVIC),pred)
install.packages("reshape")
install.packages("dplyr")
setwd("~/UVG/VIII_Semestre/Data Science/Proyecto1DataScience/DatosCrudos")
temp = list.files(pattern="*.csv")
altaverapaz <- read.csv(temp[1], header = TRUE)
bajaverapaz <- read.csv(temp[2], header = TRUE)
chimaltenango <- read.csv(temp[3], header = TRUE)
chiquimula <- read.csv(temp[4], header = TRUE)
ciudadcapital <- read.csv(temp[5], header = TRUE)
elprogreso <- read.csv(temp[6], header = TRUE)
escuintla <- read.csv(temp[7], header = TRUE)
guatemala <- read.csv(temp[8], header = TRUE)
huehuetenango <- read.csv(temp[9], header = TRUE)
izabal <- read.csv(temp[10], header = TRUE)
jalapa <- read.csv(temp[11], header = TRUE)
jutiapa <- read.csv(temp[12], header = TRUE)
peten <- read.csv(temp[13], header = TRUE)
quetzaltenango <- read.csv(temp[14], header = TRUE)
quiche <- read.csv(temp[15], header = TRUE)
retalhuleu <- read.csv(temp[16], header = TRUE)
sacatepequez <- read.csv(temp[17], header = TRUE)
sanmarcos <- read.csv(temp[18], header = TRUE)
santarosa <- read.csv(temp[19], header = TRUE)
solola <- read.csv(temp[20], header = TRUE)
suchitepequez <- read.csv(temp[21], header = TRUE)
totonicapan <- read.csv(temp[22], header = TRUE)
zacapa <- read.csv(temp[23], header = TRUE)
# Revisar que las columnas sean todas iguales... que molesta R
names(bajaverapaz) <- names(altaverapaz)
names(chimaltenango) <- names(altaverapaz)
names(chiquimula) <- names(altaverapaz)
names(ciudadcapital) <- names(altaverapaz)
names(elprogreso) <- names(altaverapaz)
names(escuintla) <- names(altaverapaz)
names(guatemala) <- names(altaverapaz)
names(huehuetenango) <- names(altaverapaz)
names(izabal) <- names(altaverapaz)
names(jutiapa) <- names(altaverapaz)
names(jalapa) <- names(altaverapaz)
names(peten) <- names(altaverapaz)
names(quetzaltenango) <- names(altaverapaz)
names(quiche) <- names(altaverapaz)
names(retalhuleu) <- names(altaverapaz)
names(sacatepequez) <- names(altaverapaz)
names(suchitepequez) <- names(altaverapaz)
names(sanmarcos) <- names(altaverapaz)
names(santarosa) <- names(altaverapaz)
names(solola) <- names(altaverapaz)
names(totonicapan) <- names(altaverapaz)
names(zacapa) <- names(altaverapaz)
identical(names(altaverapaz), names(bajaverapaz))
# Union de todos los departamentos
todosDepartamentos <- rbind(altaverapaz, bajaverapaz, chimaltenango, chiquimula, ciudadcapital, elprogreso, escuintla, guatemala, huehuetenango, izabal, jalapa, jutiapa, peten, quetzaltenango, quiche, retalhuleu, sacatepequez, sanmarcos, santarosa, solola, suchitepequez, totonicapan, zacapa)
# Union de todos los departamentos
todosDepartamentos <- rbind(altaverapaz, bajaverapaz, chimaltenango, chiquimula, ciudadcapital, elprogreso, escuintla, guatemala, huehuetenango, izabal, jalapa, jutiapa, peten, quetzaltenango, quiche, retalhuleu, sacatepequez, sanmarcos, santarosa, solola, suchitepequez, totonicapan, zacapa)
# Eliminación de duplicados
options(max.print= 1000000000)
unique(todosDepartamentos)
duplicated(todosDepartamentos)
x <-todosDepartamentos %>% distinct()
library(dplyr)
x <-todosDepartamentos %>% distinct()
# Eliminación de duplicados
options(max.print= 1000000000)
unique(todosDepartamentos)
duplicated(todosDepartamentos)
x <-todosDepartamentos %>% distinct()
View(x)
colnames(x) <- x[2,]
View(x)
colnames(x) <- x[,2]
View(x)
colnames(x) <- x[2,]
x <- x[c(-1,-2),]
View(x)
x <-todosDepartamentos %>% distinct()
View(x)
tmp <- readLines(x)[-1]
names(x) <- x[1, ]
names(x) <- x[1, ]
x <- x[-1, ]
x
View(x)
duplicated(todosDepartamentos)
x <-todosDepartamentos %>% distinct()
View(x)
x
View(x)
View(x)
x <- x[-1, ]
x <-todosDepartamentos %>% distinct()
names(x) <- as.matrix(x[1, ])
duplicated(todosDepartamentos)
no_dup <-todosDepartamentos %>% distinct()
names(no_dup) <- as.matrix(no_dup[1, ])
no_dup <- no_dup[-1, ]
no_dup[] <- lapply(no_dup, function(x) type.convert(as.character(x)))
no_dup
View(no_dup)
